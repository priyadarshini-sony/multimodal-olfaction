{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c60e5ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 3 4 6] TEST: [1 2 5 7]\n",
      "TRAIN: [1 2 5 7] TEST: [0 3 4 6]\n",
      "TRAIN: [0 1 4 5] TEST: [2 3 6 7]\n",
      "TRAIN: [2 3 6 7] TEST: [0 1 4 5]\n"
     ]
    }
   ],
   "source": [
    "from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])\n",
    "y = np.array([[0,0], [0,0], [0,1], [0,1], [1,1], [1,1], [1,0], [1,0]])\n",
    "\n",
    "rmskf = RepeatedMultilabelStratifiedKFold(n_splits=2, n_repeats=2, random_state=0)\n",
    "\n",
    "for train_index, test_index in rmskf.split(X, y):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278f9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from iterstrat.ml_stratifiers import RepeatedMultilabelStratifiedKFold\n",
    "from mordred import Calculator, descriptors\n",
    "from rdkit import Chem\n",
    "\n",
    "from rdkit.Chem import AllChem, Draw, Descriptors, PandasTools\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "import rdkit\n",
    "import networkx as nx\n",
    "\n",
    "# import deepsmiles\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25800f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e57a7da-a5a0-4f58-8764-7c96f6f648d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sv_dir='/home/is/pei-ga/Sony/data_multi'\n",
    "sv_dir = '/home/ubuntu/work/multi-modal/data_multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c794beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smi_preprocessing(smi_sequence):\n",
    "    splited_smis=[]\n",
    "    length=[]\n",
    "    end=\"/n\"\n",
    "    begin=\"&\"\n",
    "    element_table=[\"C\",\"N\",\"B\",\"O\",\"P\",\"S\",\"F\",\"Cl\",\"Br\",\"I\",\"(\",\")\",\"=\",\"#\"]\n",
    "    for i in range(len(smi_sequence)):\n",
    "        smi=smi_sequence[i]\n",
    "        splited_smi=[]\n",
    "        j=0\n",
    "        while j<len(smi):\n",
    "            smi_words=[]            \n",
    "            if smi[j]==\"[\":\n",
    "                smi_words.append(smi[j])\n",
    "                j=j+1\n",
    "                while smi[j]!=\"]\":\n",
    "                    smi_words.append(smi[j])\n",
    "                    j=j+1\n",
    "                smi_words.append(smi[j])\n",
    "                words = ''.join(smi_words)\n",
    "                splited_smi.append(words)\n",
    "                j=j+1\n",
    "\n",
    "            else:\n",
    "                smi_words.append(smi[j])\n",
    "\n",
    "                if j+1<len(smi[j]):\n",
    "                    smi_words.append(smi[j+1])\n",
    "                    words = ''.join(smi_words)\n",
    "                else:\n",
    "                    smi_words.insert(0,smi[j-1])\n",
    "                    words = ''.join(smi_words)\n",
    "\n",
    "                if words not in element_table:\n",
    "                    splited_smi.append(smi[j])\n",
    "                    j=j+1\n",
    "                else:\n",
    "                    splited_smi.append(words)\n",
    "                    j=j+2\n",
    "\n",
    "        splited_smi.append(end)\n",
    "        splited_smi.insert(0,begin)\n",
    "        splited_smis.append(splited_smi)\n",
    "    return splited_smis\n",
    "\n",
    "\n",
    "def smi2id(smiles,vocalbulary):\n",
    "    sequence_id=[]\n",
    "    for i in range(len(smiles)):\n",
    "        smi_id=[]\n",
    "        for j in range(len(smiles[i])):\n",
    "            smi_id.append(vocalbulary.index(smiles[i][j]))\n",
    "        sequence_id.append(smi_id)\n",
    "    return sequence_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7faffc5b-0741-4840-abff-705d3fef4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16280/559500 [00:09<05:32, 1633.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m fragment \u001b[39min\u001b[39;00m i\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     22\u001b[0m     mol \u001b[39m=\u001b[39m Chem\u001b[39m.\u001b[39mMolFromSmiles(fragment)\n\u001b[0;32m---> 23\u001b[0m     randomized_fragments\u001b[39m.\u001b[39mappend(Chem\u001b[39m.\u001b[39;49mMolToSmiles(mol, doRandom\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, canonical\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m     24\u001b[0m shuffle(randomized_fragments)\n\u001b[1;32m     25\u001b[0m structure \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(randomized_fragments)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(f\"{sv_dir}/labels.csv\")\n",
    "smiles = labels[['cid','smiles']]\n",
    "dict_CID_smile = dict(zip(smiles['cid'],smiles['smiles']))\n",
    "\n",
    "y = labels.iloc[:,3:].to_numpy()\n",
    "\n",
    "y.shape\n",
    "\n",
    "X_smiles=[]\n",
    "for i in smiles['smiles']:\n",
    "    #X_smiles.append(converter.encode(i))\n",
    "    X_smiles.append(i)\n",
    "len(X_smiles)\n",
    "\n",
    "\n",
    "# maximum random\n",
    "random_smiles=[]\n",
    "dupli_smiles = np.array(X_smiles*100).reshape(-1,5595).T.flatten()\n",
    "for i in tqdm(dupli_smiles):\n",
    "    randomized_fragments = []\n",
    "    for fragment in i.split('.'):\n",
    "        mol = Chem.MolFromSmiles(fragment)\n",
    "        randomized_fragments.append(Chem.MolToSmiles(mol, doRandom=True, canonical=False))\n",
    "    shuffle(randomized_fragments)\n",
    "    structure = '.'.join(randomized_fragments)\n",
    "    while structure in set(random_smiles):\n",
    "        for fragment in i.split('.'):\n",
    "            mol = Chem.MolFromSmiles(fragment)\n",
    "            randomized_fragments.append(Chem.MolToSmiles(mol, doRandom=True, canonical=False))\n",
    "        shuffle(randomized_fragments)\n",
    "        structure = '.'.join(randomized_fragments)\n",
    "    else:\n",
    "        random_smiles.append(structure)\n",
    "\n",
    "\n",
    "# after_smiles=[]\n",
    "# for i in random_smiles:\n",
    "#     after_smiles.append(converter.encode(i))\n",
    "    \n",
    "after_smiles=random_smiles\n",
    "\n",
    "smi=smi_preprocessing(after_smiles)\n",
    "print(smi[0])\n",
    "\n",
    "\n",
    "vocalbulary=[]\n",
    "for i in smi:\n",
    "    vocalbulary.extend(i)\n",
    "vocalbulary=list(set(vocalbulary))\n",
    "\n",
    "print(vocalbulary, len(vocalbulary))\n",
    "\n",
    "docs = dict(zip(vocalbulary, range(len(vocalbulary))))\n",
    "print(docs)\n",
    "\n",
    "val_id=smi2id(smi,vocalbulary)\n",
    "print(val_id[0])\n",
    "\n",
    "tensor_X = [torch.tensor(i) for i in val_id]\n",
    "tensor_X = rnn_utils.pad_sequence(tensor_X, batch_first=True)\n",
    "\n",
    "tensor_X.shape\n",
    "\n",
    "X = tensor_X.reshape(-1).reshape(-1,1660)\n",
    "X = X.reshape(5595,10,-1)\n",
    "\n",
    "X = np.asarray(X,dtype=object)\n",
    "\n",
    "X_sequence = X.transpose(0,2,1)\n",
    "\n",
    "print(X_sequence.shape,y.shape)\n",
    "\n",
    "X_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e96d9-d67d-4fc7-99ef-23dc31f55010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26, 26, 26, ..., 26, 26, 26],\n",
       "       [38, 38, 38, ..., 38, 38, 38],\n",
       "       [44, 38, 38, ..., 38, 44, 35],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e6e93-3e01-43e6-8882-74763fdcdf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### graph ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e965ee-629c-40ca-b84d-5e22cd4d1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm9_edges(g):\n",
    "    remove_edges = []\n",
    "    e={}    \n",
    "    for n1, n2, d in g.edges(data=True):\n",
    "        e_t = []\n",
    "        # Raw distance function\n",
    "        if d['b_type'] is None:\n",
    "            remove_edges += [(n1, n2)]\n",
    "        else:\n",
    "            #e_t.append(d['distance'])\n",
    "            e_t += [int(d['b_type'] == x) for x in [rdkit.Chem.rdchem.BondType.SINGLE, rdkit.Chem.rdchem.BondType.DOUBLE,\n",
    "                                                    rdkit.Chem.rdchem.BondType.TRIPLE, rdkit.Chem.rdchem.BondType.AROMATIC]]\n",
    "        if e_t:\n",
    "            e[(n1, n2)] = e_t\n",
    "    for edg in remove_edges:\n",
    "        g.remove_edge(*edg)    \n",
    "    \n",
    "    return nx.to_numpy_matrix(g), e\n",
    "    \n",
    "def qm9_nodes(g, hydrogen=False):\n",
    "    h = []\n",
    "    for n, d in g.nodes(data=True): \n",
    "        h_t = []\n",
    "        # Atom type (One-hot H, C, N, O F)\n",
    "        h_t += [int(d['a_type'] == x) for x in ['H', 'C', 'N', 'O', 'F']]\n",
    "        # Atomic number\n",
    "        h_t.append(d['a_num'])\n",
    "        # Acceptor\n",
    "        h_t.append(d['acceptor'])\n",
    "        # Donor\n",
    "        h_t.append(d['donor'])\n",
    "        # Aromatic\n",
    "        h_t.append(int(d['aromatic']))\n",
    "        # If number hydrogen is used as a\n",
    "        if hydrogen:\n",
    "            h_t.append(d['num_h'])\n",
    "        h.append(h_t)\n",
    "    return h\n",
    "\n",
    "def xyz_graph_reader(CID):\n",
    "    smiles = dict_CID_smile[CID]\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    m = Chem.AddHs(m)\n",
    "   \n",
    "    g = nx.Graph()\n",
    "    # Create nodes\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        atom_i = m.GetAtomWithIdx(i)\n",
    "\n",
    "        g.add_node(i, a_type=atom_i.GetSymbol(), a_num=atom_i.GetAtomicNum(), acceptor=0, donor=0,\n",
    "                   aromatic=atom_i.GetIsAromatic(), hybridization=atom_i.GetHybridization(),\n",
    "                   num_h=atom_i.GetTotalNumHs())\n",
    "\n",
    "\n",
    "    # Read Edges\n",
    "    for i in range(0, m.GetNumAtoms()):\n",
    "        for j in range(0, m.GetNumAtoms()):\n",
    "            e_ij = m.GetBondBetweenAtoms(i, j)\n",
    "            if e_ij is not None:\n",
    "                g.add_edge(i, j, b_type=e_ij.GetBondType())\n",
    "            else:\n",
    "                # Unbonded\n",
    "                g.add_edge(i, j, b_type=None)\n",
    "    \n",
    "    l = labels[labels['cid'] ==CID]\n",
    "    l = l.iloc[:,3:].values       \n",
    "                \n",
    "    return g , l\n",
    "\n",
    "class Qm9():\n",
    "    # Constructor\n",
    "    def __init__(self, idx, vertex_transform=qm9_nodes, edge_transform=qm9_edges,\n",
    "                 target_transform=None, e_representation='raw_distance'):\n",
    "        self.idx = idx\n",
    "        self.vertex_transform = vertex_transform\n",
    "        self.edge_transform = edge_transform\n",
    "        self.target_transform = target_transform\n",
    "        self.e_representation = e_representation\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        g, target = xyz_graph_reader(self.idx[index])\n",
    "        if self.vertex_transform is not None:\n",
    "            h = self.vertex_transform(g)\n",
    "\n",
    "        if self.edge_transform is not None:\n",
    "            g, e = self.edge_transform(g)\n",
    "\n",
    "#         if self.target_transform is not None:\n",
    "#             target = self.target_transform(target)\n",
    "\n",
    "        #g：adjacent matrix\n",
    "        #h：node properties（list of list）\n",
    "        #e：diction，key:edge，value:properties\n",
    "        return (g, h, e)\n",
    "        #return (g, h, e), target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "\n",
    "#     def set_target_transform(self, target_transform):\n",
    "#         self.target_transform = target_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d36b6b-fad8-4e0d-aa4d-1ad792afd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Qm9(smiles['cid'].values, edge_transform=qm9_edges, e_representation=\"raw_distance\")\n",
    "feat = []\n",
    "for i in range(len(data)):\n",
    "    feat.append(data[i][0])\n",
    "X_graph= np.asarray(data,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b398c9-539b-4933-8976-162f57933463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582ac40-ea77-4b60-a7b7-4902a103006f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6192bd-acf8-49e8-baf1-511f958fa57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfed0b-d329-4d9b-9f1e-28c28610ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### numeric ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc26316-7f51-4865-830a-09eb14d0d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric = pd.read_csv(f\"{sv_dir}/mordred_prune.csv\")\n",
    "del X_numeric[\"smiles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dec703-7a7f-4ca6-a2a3-c4dc867b763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numeric = X_numeric.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd16b5bb-bc35-40e5-842f-e5f908aece65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c14eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5595, 166, 10) <class 'numpy.ndarray'> (5595, 3) <class 'numpy.ndarray'> (5595, 1388) <class 'numpy.ndarray'> (5595, 91)\n"
     ]
    }
   ],
   "source": [
    "print(X_sequence.shape, type(X_sequence),X_graph.shape,type(X_graph),X_numeric.shape,type(X_numeric),y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bb5aa-8055-44e1-a938-a49e9317edce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cdd66-71b7-4f24-a7a7-606ce8c1a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(5595):\n",
    "    #sample_numeric = list(X_numeric.values[i])\n",
    "    #sample = [X_sequence[i],X_graph[i][0],X_graph[i][1],X_graph[i][2],sample_numeric]\n",
    "    sample = [X_graph[i][0],X_graph[i][1],X_graph[i][2],X_numeric[i],X_sequence[i]]\n",
    "    result.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893eaa4c-a33c-412a-9d13-2b4b64b9efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(result,dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7883f3-2ad6-4ce4-b416-b9918a4fc314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [   0    1    2 ... 5589 5592 5594] TEST: [   8   15   16 ... 5590 5591 5593]\n",
      "Len TRAIN: 4476 TEST: 1119\n",
      "TRAIN: [   1    2    3 ... 5592 5593 5594] TEST: [   0    5    9 ... 5580 5588 5589]\n",
      "Len TRAIN: 4485 TEST: 1110\n",
      "TRAIN: [   0    1    2 ... 5592 5593 5594] TEST: [   3   11   19 ... 5574 5577 5581]\n",
      "Len TRAIN: 4478 TEST: 1117\n",
      "TRAIN: [   0    3    4 ... 5590 5591 5593] TEST: [   1    2    6 ... 5579 5592 5594]\n",
      "Len TRAIN: 4460 TEST: 1135\n",
      "TRAIN: [   0    1    2 ... 5592 5593 5594] TEST: [   4    7   10 ... 5584 5586 5587]\n",
      "Len TRAIN: 4481 TEST: 1114\n",
      "TRAIN: [   0    1    3 ... 5592 5593 5594] TEST: [   2    6    8 ... 5583 5586 5589]\n",
      "Len TRAIN: 4493 TEST: 1102\n",
      "TRAIN: [   0    1    2 ... 5590 5591 5592] TEST: [   3   15   17 ... 5584 5593 5594]\n",
      "Len TRAIN: 4478 TEST: 1117\n",
      "TRAIN: [   0    1    2 ... 5592 5593 5594] TEST: [   5    7   16 ... 5585 5590 5591]\n",
      "Len TRAIN: 4463 TEST: 1132\n",
      "TRAIN: [   0    1    2 ... 5592 5593 5594] TEST: [  10   11   12 ... 5582 5587 5588]\n",
      "Len TRAIN: 4507 TEST: 1088\n",
      "TRAIN: [   2    3    5 ... 5591 5593 5594] TEST: [   0    1    4 ... 5576 5581 5592]\n",
      "Len TRAIN: 4439 TEST: 1156\n",
      "TRAIN: [   0    1    2 ... 5590 5592 5593] TEST: [   3    9   13 ... 5589 5591 5594]\n",
      "Len TRAIN: 4446 TEST: 1149\n",
      "TRAIN: [   0    2    3 ... 5591 5593 5594] TEST: [   1   11   17 ... 5578 5582 5592]\n",
      "Len TRAIN: 4490 TEST: 1105\n",
      "TRAIN: [   1    2    3 ... 5592 5593 5594] TEST: [   0    5    8 ... 5570 5576 5590]\n",
      "Len TRAIN: 4480 TEST: 1115\n",
      "TRAIN: [   0    1    2 ... 5591 5592 5594] TEST: [   4   12   14 ... 5585 5587 5593]\n",
      "Len TRAIN: 4469 TEST: 1126\n",
      "TRAIN: [   0    1    3 ... 5592 5593 5594] TEST: [   2    6    7 ... 5581 5584 5588]\n",
      "Len TRAIN: 4495 TEST: 1100\n"
     ]
    }
   ],
   "source": [
    "rmskf = RepeatedMultilabelStratifiedKFold(n_splits=5, n_repeats=3)\n",
    "for i, (train_index, test_index) in enumerate(rmskf.split(X, y)):\n",
    "\n",
    "    sv_path = f\"{sv_dir}/split_{i}.pkl\"\n",
    "\n",
    "    if os.path.exists(sv_path):\n",
    "        continue\n",
    "\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    print(\"Len TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # check label distribution\n",
    "    #print(label_dist((y_train)))\n",
    "    #print(label_dist((y_test)))\n",
    "\n",
    "    data = {}\n",
    "    data[\"X_train\"] = X_train\n",
    "    data[\"X_test\"] = X_test\n",
    "    data[\"y_train\"] = y_train\n",
    "    data[\"y_test\"] = y_test\n",
    "    data[\"train_index\"] = train_index\n",
    "    data[\"test_index\"] = test_index\n",
    "\n",
    "    with open(sv_path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13faf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb7acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b97e399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
